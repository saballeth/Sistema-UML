import re
from typing import Dict, List, Optional

class AdvancedDiagramClassifier:
    """
    Clasificador avanzado para determinar el tipo de diagrama UML necesario
    bas√°ndose en descripciones textuales de usuarios.
    
    Caracter√≠sticas:
    - An√°lisis multi-nivel (t√©rminos decisivos, densidad de keywords, contexto, industria)
    - Gesti√≥n de contexto conversacional por usuario
    - Baja latencia y alta precisi√≥n para textos t√©cnicos
    - Sin dependencias externas pesadas
    """
    
    def __init__(self):
        self.conversation_context = {}
        
        # Modelo de lenguaje mejorado con contexto
        self.domain_keywords = {
            'class_domain': [
                'clase', 'atributo', 'm√©todo', 'herencia', 'implementaci√≥n', 
                'interface', 'enum', 'propiedad', 'encapsulamiento', 'polimorfismo',
                'entidad', 'objeto', 'instancia', 'constructor', 'getter', 'setter',
                'abstracto', 'static', 'final', 'paquete', 'importar', 'miembro',
                'variable', 'funci√≥n', 'operaci√≥n', 'signatura', 'par√°metro',
                'visibilidad', 'modificador', 'sobrescritura', 'sobrecarga'
            ],
            
            'usecase_domain': [
                'actor', 'usuario', 'sistema', 'funcionalidad', 'interact√∫a',
                'realiza', 'ejecuta', 'escenario', 'caso de uso', 'requisito',
                'objetivo', 'proceso', 'flujo', 'paso', 'acci√≥n', 'tarea',
                'rol', 'responsabilidad', 'permiso', 'acceso', 'operaci√≥n',
                'actividad', 'workflow', 'procedimiento', 'secuencia', 'interacci√≥n'
            ]
        }
        
        self.industry_context = {
            'software': [
                'c√≥digo', 'programa', 'aplicaci√≥n', 'software', 'desarrollo', 
                'debug', 'compilar', 'ejecutar', 'framework', 'librer√≠a',
                'api', 'sdk', 'ide', 'repositorio', 'commit', 'branch'
            ],
            'business': [
                'negocio', 'cliente', 'venta', 'marketing', 'estrategia', 
                'mercado', 'producto', 'servicio', 'empresa', 'organizaci√≥n',
                'departamento', 'equipo', 'proyecto', 'recurso', 'presupuesto'
            ],
            'education': [
                'curso', 'estudiante', 'profesor', 'lecci√≥n', 'examen', 
                'calificaci√≥n', 'universidad', 'colegio', 'clase', 'tema',
                'asignatura', 'materia', 'plan de estudios', 'curr√≠culo'
            ],
            'database': [
                'tabla', 'registro', 'campo', 'consulta', 'sql', 'entidad',
                'relaci√≥n', 'clave', '√≠ndice', 'transacci√≥n', 'esquema'
            ]
        }
        
        self.confidence_thresholds = {
            'initial': 0.6,
            'with_context': 0.75,
            'high_confidence': 0.85
        }

    def analyze_conversation(self, user_id: str, text: str, is_follow_up: bool = False) -> Dict:
        """
        Analiza el texto considerando el contexto de la conversaci√≥n y determina
        el tipo de diagrama UML m√°s apropiado.
        
        Args:
            user_id: Identificador √∫nico del usuario
            text: Descripci√≥n textual del sistema/diagrama
            is_follow_up: Indica si es un mensaje de seguimiento
            
        Returns:
            Dict con informaci√≥n del an√°lisis:
            - intent: 'diagrama_clases', 'diagrama_casos_uso', o 'unknown'
            - confidence: Nivel de confianza (0.0 a 1.0)
            - method: M√©todo utilizado para la clasificaci√≥n
            - supporting_analyses: N√∫mero de an√°lisis que apoyan la decisi√≥n
        """
        # Inicializar contexto si es nuevo usuario
        if user_id not in self.conversation_context:
            self.conversation_context[user_id] = {
                'messages': [],
                'detected_domain': None,
                'confidence_history': [],
                'last_intent': None,
                'industry_hints': set(),
                'interaction_count': 0
            }
        
        context = self.conversation_context[user_id]
        context['messages'].append(text)
        context['interaction_count'] += 1
        
        # An√°lisis multi-nivel
        basic_analysis = self._basic_intent_detection(text)
        contextual_analysis = self._contextual_analysis(text, context)
        industry_analysis = self._industry_analysis(text)
        semantic_analysis = self._semantic_analysis(text)
        
        # Combinar an√°lisis
        final_result = self._combine_analyses(
            basic_analysis, contextual_analysis, industry_analysis, semantic_analysis, context, is_follow_up
        )
        
        # Actualizar contexto
        self._update_conversation_context(user_id, final_result, industry_analysis)
        
        return final_result

    def _basic_intent_detection(self, text: str) -> Dict:
        """Detecci√≥n b√°sica de intenci√≥n basada en palabras clave"""
        text_lower = text.lower()
        
        # Contar ocurrencias por dominio
        class_score = sum(1 for word in self.domain_keywords['class_domain'] if word in text_lower)
        usecase_score = sum(1 for word in self.domain_keywords['usecase_domain'] if word in text_lower)
        
        # Detectar t√©rminos decisivos (alta especificidad)
        decisive_terms = {
            'diagrama_clases': [
                'clase', 'atributo', 'm√©todo', 'herencia', 'polimorfismo',
                'encapsulamiento', 'interface', 'implementaci√≥n'
            ],
            'diagrama_casos_uso': [
                'actor', 'caso de uso', 'interact√∫a', 'funcionalidad', 'escenario',
                'requisito funcional'
            ]
        }
        
        decisive_class = any(term in text_lower for term in decisive_terms['diagrama_clases'])
        decisive_usecase = any(term in text_lower for term in decisive_terms['diagrama_casos_uso'])
        
        # Si hay t√©rminos decisivos de un tipo sin t√©rminos del otro tipo
        if decisive_class and not decisive_usecase:
            return {'intent': 'diagrama_clases', 'confidence': 0.92, 'method': 'decisive_terms'}
        elif decisive_usecase and not decisive_class:
            return {'intent': 'diagrama_casos_uso', 'confidence': 0.92, 'method': 'decisive_terms'}
        
        # Scoring basado en densidad de t√©rminos
        total_keywords = class_score + usecase_score
        if total_keywords > 0:
            class_ratio = class_score / total_keywords
            usecase_ratio = usecase_score / total_keywords
            
            # Diferencia significativa favorece un tipo
            difference = abs(class_ratio - usecase_ratio)
            if difference > 0.3:  # Diferencia del 30% o m√°s
                intent = 'diagrama_clases' if class_ratio > usecase_ratio else 'diagrama_casos_uso'
                confidence = 0.7 + (difference * 0.3)  # Escalar confianza basada en diferencia
                return {'intent': intent, 'confidence': min(confidence, 0.9), 'method': 'keyword_density'}
            elif difference > 0.15:  # Diferencia moderada
                intent = 'diagrama_clases' if class_ratio > usecase_ratio else 'diagrama_casos_uso'
                confidence = 0.6 + (difference * 0.2)
                return {'intent': intent, 'confidence': confidence, 'method': 'keyword_density'}
        
        return {'intent': 'unknown', 'confidence': 0.4, 'method': 'basic_analysis'}

    def _contextual_analysis(self, text: str, context: Dict) -> Dict:
        """An√°lisis considerando el contexto de la conversaci√≥n previa"""
        # Si no hay contexto previo, no podemos hacer an√°lisis contextual
        if not context['detected_domain'] and context['interaction_count'] <= 1:
            return {'intent': 'unknown', 'confidence': 0.0, 'method': 'no_context'}
        
        previous_intent = context['last_intent']
        if previous_intent and previous_intent != 'unknown':
            # Verificar consistencia con contexto
            text_lower = text.lower()
            relevant_terms = self.domain_keywords[
                'class_domain' if previous_intent == 'diagrama_clases' else 'usecase_domain'
            ]
            
            term_matches = sum(1 for term in relevant_terms if term in text_lower)
            
            if term_matches > 0:
                # Boost basado en n√∫mero de t√©rminos coincidentes e historial
                confidence_boost = min(0.4, term_matches * 0.1)
                
                # Boost adicional por historial consistente
                if len(context['confidence_history']) > 1:
                    recent_confidences = context['confidence_history'][-3:]  # √öltimas 3 interacciones
                    avg_recent_confidence = sum(recent_confidences) / len(recent_confidences)
                    if avg_recent_confidence > 0.7:
                        confidence_boost += 0.1
                
                base_confidence = 0.7 if context['detected_domain'] else 0.6
                return {
                    'intent': previous_intent, 
                    'confidence': min(base_confidence + confidence_boost, 0.95),
                    'method': 'context_reinforcement'
                }
        
        return {'intent': 'unknown', 'confidence': 0.0, 'method': 'context_analysis'}

    def _industry_analysis(self, text: str) -> Dict:
        """An√°lisis de contexto de industria para inferir tipo de diagrama"""
        text_lower = text.lower()
        industry_scores = {}
        
        for industry, keywords in self.industry_context.items():
            industry_scores[industry] = sum(1 for keyword in keywords if keyword in text_lower)
        
        # Encontrar industria predominante
        primary_industry = max(industry_scores, key=industry_scores.get)
        max_score = industry_scores[primary_industry]
        
        if max_score > 0:
            # Mapeo industria -> preferencia de diagrama
            industry_preference = {
                'software': 'diagrama_clases',
                'business': 'diagrama_casos_uso', 
                'education': 'diagrama_clases',
                'database': 'diagrama_clases'
            }
            
            preferred_intent = industry_preference.get(primary_industry, 'unknown')
            
            # Calcular confianza basada en score y presencia de t√©rminos clave
            base_confidence = min(0.7, max_score * 0.15)
            
            # Boost si hay t√©rminos fuertes de la industria
            strong_industry_terms = {
                'software': ['c√≥digo', 'programa', 'desarrollo'],
                'business': ['negocio', 'cliente', 'venta'],
                'education': ['curso', 'estudiante', 'profesor'],
                'database': ['tabla', 'registro', 'consulta']
            }
            
            strong_terms_count = sum(1 for term in strong_industry_terms.get(primary_industry, []) 
                                   if term in text_lower)
            if strong_terms_count > 0:
                base_confidence += 0.1
            
            return {
                'intent': preferred_intent,
                'confidence': base_confidence,
                'method': f'industry_{primary_industry}'
            }
        
        return {'intent': 'unknown', 'confidence': 0.0, 'method': 'industry_analysis'}

    def _semantic_analysis(self, text: str) -> Dict:
        """An√°lisis sem√°ntico basado en patrones y estructura del texto"""
        text_lower = text.lower()
        
        # Patrones que indican diagrama de clases
        class_patterns = [
            r'\b(clase|class)\s+\w+\s*\{',  # "clase Usuario {"
            r'\b(public|private|protected)\s+\w+',  # modificadores de acceso
            r'\w+\s+\w+\s*\([^)]*\)',  # declaraciones de m√©todos
            r'\b(extends|implements)\b',  # herencia/implementaci√≥n
        ]
        
        # Patrones que indican diagrama de casos de uso
        usecase_patterns = [
            r'\b(actor|usuario)\s+\w+',  # "actor Cliente"
            r'\b(caso de uso|use case)\s+\w+',  # "caso de uso Login"
            r'\b(puede|pueden)\s+\w+',  # "los usuarios pueden realizar X"
            r'\b(sistema|sistem)\s+\w+',  # "el sistema debe hacer X"
        ]
        
        class_pattern_matches = sum(1 for pattern in class_patterns if re.search(pattern, text_lower))
        usecase_pattern_matches = sum(1 for pattern in usecase_patterns if re.search(pattern, text_lower))
        
        if class_pattern_matches > usecase_pattern_matches and class_pattern_matches > 0:
            confidence = min(0.8, 0.5 + (class_pattern_matches * 0.1))
            return {'intent': 'diagrama_clases', 'confidence': confidence, 'method': 'semantic_patterns'}
        elif usecase_pattern_matches > class_pattern_matches and usecase_pattern_matches > 0:
            confidence = min(0.8, 0.5 + (usecase_pattern_matches * 0.1))
            return {'intent': 'diagrama_casos_uso', 'confidence': confidence, 'method': 'semantic_patterns'}
        
        return {'intent': 'unknown', 'confidence': 0.0, 'method': 'semantic_analysis'}

    def _combine_analyses(self, basic: Dict, contextual: Dict, industry: Dict, 
                         semantic: Dict, context: Dict, is_follow_up: bool) -> Dict:
        """Combina todos los an√°lisis para tomar una decisi√≥n final"""
        analyses = [basic, contextual, industry, semantic]
        
        # Filtrar an√°lisis con confianza suficiente
        valid_analyses = [a for a in analyses if a['confidence'] > 0.3]
        
        if not valid_analyses:
            return {
                'intent': 'unknown', 
                'confidence': 0.3, 
                'method': 'low_confidence_combination',
                'supporting_analyses': 0
            }
        
        # Agrupar por intenci√≥n
        intent_scores = {}
        for analysis in valid_analyses:
            intent = analysis['intent']
            if intent not in intent_scores:
                intent_scores[intent] = []
            intent_scores[intent].append(analysis['confidence'])
        
        # Calcular score promedio por intenci√≥n
        avg_scores = {}
        for intent, scores in intent_scores.items():
            avg_scores[intent] = sum(scores) / len(scores)
        
        # Aplicar boosts estrat√©gicos
        if is_follow_up and context['last_intent'] in avg_scores:
            # Boost por consistencia en conversaci√≥n
            avg_scores[context['last_intent']] += 0.15
        
        # Boost por m√∫ltiples an√°lisis coincidentes
        for intent, scores in intent_scores.items():
            if len(scores) >= 2:
                avg_scores[intent] += 0.1
            if len(scores) >= 3:
                avg_scores[intent] += 0.05
        
        # Seleccionar intenci√≥n con mayor score
        if avg_scores:
            # Ordenar intents por score
            sorted_intents = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)
            best_intent, best_score = sorted_intents[0]
            second_score = sorted_intents[1][1] if len(sorted_intents) > 1 else 0.0

            # Detectar ambig√ºedad: si la diferencia entre top2 es peque√±a o la mejor puntuaci√≥n es baja
            score_diff = best_score - second_score
            # criterios: diferencia menor a 0.08 (8%) o mejor score < 0.55 => ambiguous
            if score_diff < 0.08 or best_score < 0.55:
                ambiguity_reason = []
                if score_diff < 0.08:
                    ambiguity_reason.append(f"small_score_diff={score_diff:.2f}")
                if best_score < 0.55:
                    ambiguity_reason.append(f"low_best_score={best_score:.2f}")

                return {
                    'intent': 'ambiguous',
                    'confidence': round(best_score, 2),
                    'method': 'ambiguous_detection',
                    'supporting_analyses': sum(len(v) for v in intent_scores.values()),
                    'ambiguity_reason': ",".join(ambiguity_reason) if ambiguity_reason else 'undetermined',
                    'analysis_breakdown': {
                        'basic': basic,
                        'contextual': contextual,
                        'industry': industry,
                        'semantic': semantic,
                        'avg_scores': avg_scores
                    }
                }

            best_confidence = min(best_score, 0.95)  # Cap at 0.95
            supporting_analyses = len(intent_scores[best_intent])

            # Ajuste final de confianza basado en n√∫mero de an√°lisis de apoyo
            if supporting_analyses >= 2:
                best_confidence = min(1.0, best_confidence + 0.05)
            if supporting_analyses >= 3:
                best_confidence = min(1.0, best_confidence + 0.03)

            return {
                'intent': best_intent,
                'confidence': best_confidence,
                'method': 'combined_analysis',
                'supporting_analyses': supporting_analyses,
                'analysis_breakdown': {
                    'basic': basic,
                    'contextual': contextual,
                    'industry': industry,
                    'semantic': semantic
                }
            }
        
        return {
            'intent': 'unknown', 
            'confidence': 0.4, 
            'method': 'fallback',
            'supporting_analyses': 0
        }

    def _update_conversation_context(self, user_id: str, result: Dict, industry_analysis: Dict):
        """Actualiza el contexto de la conversaci√≥n para futuras interacciones"""
        context = self.conversation_context[user_id]
        
        # Actualizar intenci√≥n detectada si hay alta confianza
        if result['confidence'] > self.confidence_thresholds['with_context']:
            context['detected_domain'] = result['intent']
        
        context['last_intent'] = result['intent']
        context['confidence_history'].append(result['confidence'])
        
        # Mantener solo las √∫ltimas 10 confianzas en el historial
        if len(context['confidence_history']) > 10:
            context['confidence_history'] = context['confidence_history'][-10:]
        
        # Actualizar pistas de industria
        if industry_analysis['method'].startswith('industry_'):
            industry = industry_analysis['method'].replace('industry_', '')
            context['industry_hints'].add(industry)

    def classify_diagram_type(self, description: str, user_id: str = "default") -> Dict:
        """
        Clasifica el tipo de diagrama bas√°ndose en una descripci√≥n.
        
        Args:
            description: Descripci√≥n textual del sistema/diagrama
            user_id: Identificador del usuario (opcional)
            
        Returns:
            Dict con el resultado de la clasificaci√≥n
        """
        return self.analyze_conversation(user_id, description, is_follow_up=False)

    def get_user_context(self, user_id: str) -> Optional[Dict]:
        """Obtiene el contexto actual de un usuario espec√≠fico"""
        return self.conversation_context.get(user_id)
    
    def clear_user_context(self, user_id: str):
        """Limpia el contexto de un usuario espec√≠fico"""
        if user_id in self.conversation_context:
            del self.conversation_context[user_id]
    
    def get_classification_stats(self) -> Dict:
        """Obtiene estad√≠sticas generales del clasificador"""
        total_users = len(self.conversation_context)
        active_conversations = sum(1 for ctx in self.conversation_context.values() 
                                 if ctx['interaction_count'] > 1)
        
        return {
            'total_users': total_users,
            'active_conversations': active_conversations,
            'conversation_context': self.conversation_context
        }


# Funciones de utilidad para uso r√°pido
def quick_classify(description: str) -> str:
    """
    Clasificaci√≥n r√°pida sin mantener contexto de conversaci√≥n.
    
    Args:
        description: Descripci√≥n textual del diagrama
        
    Returns:
        String con el tipo de diagrama detectado
    """
    classifier = AdvancedDiagramClassifier()
    result = classifier.classify_diagram_type(description)
    return result['intent']

def classify_with_details(description: str) -> Dict:
    """
    Clasificaci√≥n con detalles completos del an√°lisis.
    
    Args:
        description: Descripci√≥n textual del diagrama
        
    Returns:
        Dict con resultado completo y breakdown del an√°lisis
    """
    classifier = AdvancedDiagramClassifier()
    return classifier.classify_diagram_type(description)


# Ejemplos de uso y pruebas
if __name__ == "__main__":
    # Ejemplos de prueba
    test_cases = [
        {
            "description": "Necesito un diagrama con las clases Usuario, Producto y Pedido. Cada clase tiene atributos y m√©todos espec√≠ficos.",
            "expected": "diagrama_clases"
        },
        {
            "description": "Quiero mostrar c√≥mo los actores Cliente y Administrador interact√∫an con el sistema mediante casos de uso como realizar pedido y gestionar inventario.",
            "expected": "diagrama_casos_uso"
        },
        {
            "description": "Sistema de gesti√≥n para una universidad con estudiantes, profesores y cursos.",
            "expected": "diagrama_clases"  # Por contexto educativo
        }
    ]
    
    classifier = AdvancedDiagramClassifier()
    
    print(" PRUEBAS DEL CLASIFICADOR AVANZADO")
    print("=" * 60)
    
    for i, test in enumerate(test_cases, 1):
        result = classifier.classify_diagram_type(test["description"], f"test_user_{i}")
        is_correct = result['intent'] == test['expected']
        
        print(f"\nüìù Test {i}:")
        print(f"   Descripci√≥n: {test['description'][:80]}...")
        print(f"   Esperado: {test['expected']}")
        print(f"   Obtenido: {result['intent']}")
        print(f"   Confianza: {result['confidence']:.2f}")
        print(f"   M√©todo: {result['method']}")
        print(f"   An√°lisis de apoyo: {result.get('supporting_analyses', 'N/A')}")
        print(f"   ‚úÖ CORRECTO" if is_correct else "   ‚ùå INCORRECTO")
    
    print(f"\n Estad√≠sticas: {classifier.get_classification_stats()}")